import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score

# Load the dataset
df = pd.read_excel('Dry_Bean_Dataset.xlsx')

# Checking for missing values
print(df.isnull().sum())
df.dropna(inplace=True)

# Label Encoding
label_encoder = LabelEncoder()
df['Class'] = label_encoder.fit_transform(df['Class'])

# Remove outliers using IQR method
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]

# Separate features and target
X = df.drop('Class', axis=1)
y = df['Class']
print(df.head())


import numpy as np
import random
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

def initialize_population(size, num_features):
    return [np.random.randint(0, 2, num_features) for _ in range(size)]

def fitness(chromosome, X, y):
    kmeans = KMeans(n_clusters=len(np.unique(y)), n_init=10, random_state=0)
    kmeans.fit(X * chromosome)
    score = silhouette_score(X, kmeans.labels_)
    return max(score, 0)  # Ensure non-negative fitness value

def selection(population, fitnesses, num_parents):
    fitnesses = np.array(fitnesses)
    # Ensure probabilities sum to 1 and are non-negative
    if fitnesses.sum() == 0:
        fitnesses = np.ones_like(fitnesses)
    selected = np.random.choice(len(population), size=num_parents, p=fitnesses/fitnesses.sum())
    return [population[i] for i in selected]

def crossover(parent1, parent2):
    point = random.randint(1, len(parent1)-1)
    child1 = np.concatenate((parent1[:point], parent2[point:]))
    child2 = np.concatenate((parent2[:point], parent1[point:]))
    return child1, child2

def mutation(chromosome, mutation_rate):
    for i in range(len(chromosome)):
        if random.random() < mutation_rate:
            chromosome[i] = 1 - chromosome[i]
    return chromosome

def genetic_algorithm(X, y, pop_size=50, num_generations=100, num_parents=20, mutation_rate=0.01):
    num_features = X.shape[1]
    population = initialize_population(pop_size, num_features)
    for generation in range(num_generations):
        fitnesses = np.array([fitness(chrom, X, y) for chrom in population])
        parents = selection(population, fitnesses, num_parents)
        next_population = []
        for i in range(len(parents)//2):
            parent1, parent2 = parents[2*i], parents[2*i+1]
            child1, child2 = crossover(parent1, parent2)
            next_population.extend([mutation(child1, mutation_rate), mutation(child2, mutation_rate)])
        population = next_population
    fitnesses = np.array([fitness(chrom, X, y) for chrom in population])
    best_chromosome = population[np.argmax(fitnesses)]
    return best_chromosome, max(fitnesses)

# Assuming X and y are already defined
best_chromosome, best_fitness = genetic_algorithm(X.values, y.values)
print(f'Best Chromosome: {best_chromosome}\nBest Fitness: {best_fitness}')

#Best Chromosome: [1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0]
#Best Fitness: 0.5456758038287725

# K-means clustering for comparison
kmeans = KMeans(n_clusters=len(np.unique(y)), random_state=0)
kmeans_labels = kmeans.fit_predict(X)

# Evaluate K-means
silhouette_kmeans = silhouette_score(X, kmeans_labels)
davies_bouldin_kmeans = davies_bouldin_score(X, kmeans_labels)

print(f'Silhouette Score for K-means: {silhouette_kmeans}')
print(f'Davies-Bouldin Index for K-means: {davies_bouldin_kmeans}')


# Visualization of K-means Clustering
plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=kmeans_labels, cmap='viridis')
plt.title('K-means Clustering')
plt.show()

# Applying the best chromosome to the dataset and visualizing the GA Clustering
X_ga = X * best_chromosome
kmeans_ga = KMeans(n_clusters=len(np.unique(y)), random_state=0)
kmeans_ga_labels = kmeans_ga.fit_predict(X_ga)

plt.scatter(X_ga.iloc[:, 0], X_ga.iloc[:, 1], c=kmeans_ga_labels, cmap='viridis')
plt.title('GA Clustering')
plt.show()

# Evaluate GA Clustering
silhouette_ga = silhouette_score(X_ga, kmeans_ga_labels)
davies_bouldin_ga = davies_bouldin_score(X_ga, kmeans_ga_labels)

print(f'Silhouette Score for GA: {silhouette_ga}')
print(f'Davies-Bouldin Index for GA: {davies_bouldin_ga}')
